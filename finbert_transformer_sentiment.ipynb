{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate>=0.26.0\n",
      "  Using cached accelerate-1.5.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting transformers[torch]\n",
      "  Using cached transformers-4.50.1-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers[torch])\n",
      "  Using cached huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers[torch])\n",
      "  Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers[torch])\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers[torch])\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.5)\n",
      "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.1+cu121)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0) (5.9.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->transformers[torch]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->transformers[torch]) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->transformers[torch]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->transformers[torch]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->transformers[torch]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->transformers[torch]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->transformers[torch]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->transformers[torch]) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->transformers[torch]) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0->transformers[torch]) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Using cached accelerate-1.5.2-py3-none-any.whl (345 kB)\n",
      "Using cached huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Using cached transformers-4.50.1-py3-none-any.whl (10.2 MB)\n",
      "Installing collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers, accelerate\n",
      "Successfully installed accelerate-1.5.2 huggingface-hub-0.29.3 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.50.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.50.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.14.0)\n",
      "Collecting optuna\n",
      "  Using cached optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.1.105)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.2.2)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Using cached alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
      "  Using cached sqlalchemy-2.0.39-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Using cached Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.4.2->optuna)\n",
      "  Using cached greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "Using cached optuna-4.2.1-py3-none-any.whl (383 kB)\n",
      "Using cached alembic-1.15.1-py3-none-any.whl (231 kB)\n",
      "Using cached sqlalchemy-2.0.39-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Using cached colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Using cached greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)\n",
      "Using cached Mako-1.3.9-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
      "Successfully installed Mako-1.3.9 alembic-1.15.1 colorlog-6.9.0 greenlet-3.1.1 optuna-4.2.1 sqlalchemy-2.0.39\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install \"transformers[torch]\" \"accelerate>=0.26.0\" -U\n",
    "# !pip install transformers torch scikit-learn matplotlib seaborn scipy optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import scipy\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Disable WandB logging\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                               Text\n",
       "0   neutral  According to Gran , the company has no plans t...\n",
       "1   neutral  Technopolis plans to develop in stages an area...\n",
       "2  negative  The international electronic industry company ...\n",
       "3  positive  With the new production plant the company woul...\n",
       "4  positive  According to the company 's updated strategy f..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('/data/training_data_sentiment.csv', \n",
    "                   encoding='unicode_escape',\n",
    "                   names=['Sentiment', 'Text'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4846, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape  # (4846, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string labels to numeric labels (negative -> 0, neutral -> 1, positive -> 2)\n",
    "label_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "data['Sentiment'] = data['Sentiment'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['Text'].to_list()  # List of headlines\n",
    "y = data['Sentiment'].to_list()  # Corresponding sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load FinBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FinBERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\", num_labels=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "class FinancialNewsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(X_val, truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets for training\n",
    "train_dataset = FinancialNewsDataset(train_encodings, y_train)\n",
    "val_dataset = FinancialNewsDataset(val_encodings, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters to tune\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32])\n",
    "    epochs = trial.suggest_int('epochs', 3, 5)\n",
    "\n",
    "    # Set up training arguments with suggested hyperparameters\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',                # Output directory\n",
    "        num_train_epochs=epochs,              \n",
    "        per_device_train_batch_size=batch_size,  # Batch size for training\n",
    "        per_device_eval_batch_size=batch_size,   # Batch size for evaluation\n",
    "        warmup_steps=500,                      # Number of warmup steps\n",
    "        weight_decay=0.01,                     # Weight decay\n",
    "        logging_dir='./logs',                \n",
    "        evaluation_strategy=\"epoch\",           # Evaluate after each epoch\n",
    "        save_strategy=\"epoch\",                # Save model after each epoch\n",
    "        learning_rate=learning_rate,          # Learning rate\n",
    "        load_best_model_at_end=True,        \n",
    "        metric_for_best_model=\"f1\",           # Optimize F1 score\n",
    "    )\n",
    "\n",
    "    # Prepare Trainer with F1 score as the evaluation metric\n",
    "    trainer = Trainer(\n",
    "        model=model,                         \n",
    "        args=training_args,                    \n",
    "        train_dataset=train_dataset,      \n",
    "        eval_dataset=val_dataset,          \n",
    "        compute_metrics=lambda p: {\n",
    "            'f1': f1_score(p.label_ids, p.predictions.argmax(axis=-1), average='weighted')\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "    \n",
    "    # Return the F1 score as the objective to maximize\n",
    "    f1 = trainer.evaluate()['eval_f1']\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 02:45:58,723] A new study created in memory with name: no-name-789027dd-6a4a-4677-aae3-70e8fad15145\n",
      "/tmp/ipykernel_160/341874380.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='366' max='366' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [366/366 02:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.518233</td>\n",
       "      <td>0.777684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.336210</td>\n",
       "      <td>0.863920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.420490</td>\n",
       "      <td>0.846206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 02:48:48,449] Trial 0 finished with value: 0.8639197972163158 and parameters: {'learning_rate': 4.7561269927680326e-05, 'batch_size': 32, 'epochs': 3}. Best is trial 0 with value: 0.8639197972163158.\n",
      "/tmp/ipykernel_160/341874380.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [610/610 04:39, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.429699</td>\n",
       "      <td>0.872220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.456047</td>\n",
       "      <td>0.866211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.420930</td>\n",
       "      <td>0.863503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.609644</td>\n",
       "      <td>0.828693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.583934</td>\n",
       "      <td>0.862843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 02:53:30,938] Trial 1 finished with value: 0.8722201583518476 and parameters: {'learning_rate': 0.00014692030382805008, 'batch_size': 32, 'epochs': 5}. Best is trial 1 with value: 0.8722201583518476.\n",
      "/tmp/ipykernel_160/341874380.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2425' max='2425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2425/2425 05:37, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.661689</td>\n",
       "      <td>0.869521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.606348</td>\n",
       "      <td>0.882894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.124700</td>\n",
       "      <td>0.709094</td>\n",
       "      <td>0.881065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.690008</td>\n",
       "      <td>0.882082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>0.729033</td>\n",
       "      <td>0.883207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='122' max='122' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [122/122 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 02:59:12,160] Trial 2 finished with value: 0.8832074035204507 and parameters: {'learning_rate': 1.8118842364702126e-05, 'batch_size': 8, 'epochs': 5}. Best is trial 2 with value: 0.8832074035204507.\n",
      "/tmp/ipykernel_160/341874380.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2425' max='2425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2425/2425 05:40, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.593593</td>\n",
       "      <td>0.775842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.285300</td>\n",
       "      <td>0.670018</td>\n",
       "      <td>0.804402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.518700</td>\n",
       "      <td>0.715987</td>\n",
       "      <td>0.839108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.343400</td>\n",
       "      <td>0.645125</td>\n",
       "      <td>0.864435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.200800</td>\n",
       "      <td>0.692368</td>\n",
       "      <td>0.864838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='122' max='122' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [122/122 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 03:04:56,316] Trial 3 finished with value: 0.8648382837538819 and parameters: {'learning_rate': 0.00011648661313374887, 'batch_size': 8, 'epochs': 5}. Best is trial 2 with value: 0.8832074035204507.\n",
      "/tmp/ipykernel_160/341874380.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='972' max='972' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [972/972 03:55, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.816162</td>\n",
       "      <td>0.840211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.740235</td>\n",
       "      <td>0.824041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.170500</td>\n",
       "      <td>0.736661</td>\n",
       "      <td>0.826668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.170500</td>\n",
       "      <td>0.729985</td>\n",
       "      <td>0.833114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 03:08:55,422] Trial 4 finished with value: 0.8402111938235568 and parameters: {'learning_rate': 0.00016404500430105274, 'batch_size': 16, 'epochs': 4}. Best is trial 2 with value: 0.8832074035204507.\n",
      "/tmp/ipykernel_160/341874380.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [610/610 04:40, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.769153</td>\n",
       "      <td>0.843443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.717617</td>\n",
       "      <td>0.852045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.724540</td>\n",
       "      <td>0.845148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.723865</td>\n",
       "      <td>0.861707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.796294</td>\n",
       "      <td>0.849136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 03:13:39,089] Trial 5 finished with value: 0.8617069057202004 and parameters: {'learning_rate': 3.625768355420454e-05, 'batch_size': 32, 'epochs': 5}. Best is trial 2 with value: 0.8832074035204507.\n",
      "/tmp/ipykernel_160/341874380.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1215' max='1215' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1215/1215 04:57, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.996472</td>\n",
       "      <td>0.828722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.725705</td>\n",
       "      <td>0.795792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.282300</td>\n",
       "      <td>0.845814</td>\n",
       "      <td>0.647669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.282300</td>\n",
       "      <td>0.917367</td>\n",
       "      <td>0.436242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.817500</td>\n",
       "      <td>0.917421</td>\n",
       "      <td>0.436242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 03:18:40,640] Trial 6 finished with value: 0.8287222159448133 and parameters: {'learning_rate': 0.00022068628938752685, 'batch_size': 16, 'epochs': 5}. Best is trial 2 with value: 0.8832074035204507.\n",
      "/tmp/ipykernel_160/341874380.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='972' max='972' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [972/972 03:58, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.789490</td>\n",
       "      <td>0.854087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.782520</td>\n",
       "      <td>0.860336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.825176</td>\n",
       "      <td>0.861109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.862822</td>\n",
       "      <td>0.861372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 03:22:42,955] Trial 7 finished with value: 0.8613716713891945 and parameters: {'learning_rate': 1.3555772919906526e-05, 'batch_size': 16, 'epochs': 4}. Best is trial 2 with value: 0.8832074035204507.\n",
      "/tmp/ipykernel_160/341874380.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1215' max='1215' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1215/1215 04:58, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.002543</td>\n",
       "      <td>0.841924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.957399</td>\n",
       "      <td>0.826125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.119400</td>\n",
       "      <td>0.887592</td>\n",
       "      <td>0.818016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.119400</td>\n",
       "      <td>0.895477</td>\n",
       "      <td>0.833783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.917655</td>\n",
       "      <td>0.845946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 03:27:44,770] Trial 8 finished with value: 0.8459462151592011 and parameters: {'learning_rate': 0.00012081559532748943, 'batch_size': 16, 'epochs': 5}. Best is trial 2 with value: 0.8832074035204507.\n",
      "/tmp/ipykernel_160/341874380.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='729' max='729' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [729/729 02:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.074738</td>\n",
       "      <td>0.827539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.940965</td>\n",
       "      <td>0.436242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.394800</td>\n",
       "      <td>0.919752</td>\n",
       "      <td>0.436242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 03:30:47,555] Trial 9 finished with value: 0.8275391791321268 and parameters: {'learning_rate': 0.0002580987800500476, 'batch_size': 16, 'epochs': 3}. Best is trial 2 with value: 0.8832074035204507.\n"
     ]
    }
   ],
   "source": [
    "# Create an Optuna study to maximize the F1 score\n",
    "study = optuna.create_study(direction='maximize')  # Maximize F1 score\n",
    "study.optimize(objective, n_trials=10)  # Run optimization for 10 trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 1.8118842364702126e-05, 'batch_size': 8, 'epochs': 5}\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "print(f\"Best hyperparameters: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "# Set the final training arguments based on the best parameters\n",
    "final_training_args = TrainingArguments(\n",
    "    output_dir='./results',                \n",
    "    num_train_epochs=best_params['epochs'],    \n",
    "    per_device_train_batch_size=best_params['batch_size'],\n",
    "    per_device_eval_batch_size=best_params['batch_size'],\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final trainer setup with the best hyperparameters\n",
    "final_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=final_training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=lambda p: {\n",
    "        'f1': f1_score(p.label_ids, p.predictions.argmax(axis=-1), average='weighted')\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2425' max='2425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2425/2425 05:41, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.121976</td>\n",
       "      <td>0.831575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>1.186090</td>\n",
       "      <td>0.833773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>1.250201</td>\n",
       "      <td>0.844158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>1.269341</td>\n",
       "      <td>0.835611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>1.271710</td>\n",
       "      <td>0.842009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2425, training_loss=0.03398508612642583, metrics={'train_runtime': 341.2174, 'train_samples_per_second': 56.797, 'train_steps_per_second': 7.107, 'total_flos': 1493888096358000.0, 'train_loss': 0.03398508612642583, 'epoch': 5.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain the model with the best hyperparameters\n",
    "final_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model F1 Score: 0.8441576473250432\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "eval_results = final_trainer.evaluate()\n",
    "print(f\"Final Model F1 Score: {eval_results['eval_f1']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = final_trainer.predict(val_dataset)\n",
    "conf_matrix = confusion_matrix(y_val, preds.predictions.argmax(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['negative', 'neutral', 'positive'], yticklabels=['negative', 'neutral', 'positive'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/sentiment/saved_model.zip'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì €ìž¥\n",
    "model.save_pretrained(\"./saved_model\")\n",
    "tokenizer.save_pretrained(\"./saved_model\")\n",
    "\n",
    "# 2. í´ë” ì••ì¶•\n",
    "import shutil\n",
    "shutil.make_archive(\"saved_model\", 'zip', \"./saved_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"saved_model.zip\" download> ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (saved_model.zip)</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<a href=\"saved_model.zip\" download> ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (saved_model.zip)</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 622510,
     "sourceId": 1192499,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
